{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关的库\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "from torch.optim import SGD\n",
    "import torch.utils.data as Data\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用手写字体数据，准备训练数据集\n",
    "train_data=torchvision.datasets.MNIST(\n",
    "    root=\"./data/MNIST\" ,# 数据的路径\n",
    "    train=True, # 只使用数据的训练数据集\n",
    "    # 将数据转化为torch的使用张量，取值范围为【0,1】\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False # 数据已经下载过，使用在这里不再下载\n",
    ")\n",
    "# 定义一个数据加载器\n",
    "train_loader=Data.DataLoader(\n",
    "    dataset=train_data,# 使用的数据集\n",
    "    batch_size=128,# 批处理样本大小\n",
    "    shuffle=True, # 每次迭代之前打乱数据\n",
    "    num_workers=2,# 使用两个进程\n",
    ")\n",
    " # 获取一个batch的数据\n",
    "for step,(b_x,b_y) in enumerate(train_loader):\n",
    "    if step>0:\n",
    "        break\n",
    "# 输出训练图像的尺寸和标签的尺寸\n",
    "print(\"b_x.shape:\",b_x.shape)\n",
    "print(\"b_y.shape:\",b_y.shape)\n",
    "\n",
    "# 准备需要使用的测试机数据集\n",
    "test_data=torchvision.datasets.MNIST(\n",
    "    root=\"./data/MINST\", # 数据的路径\n",
    "    train=False ,# 不使用训练数据集\n",
    "    download=False # 不下载数据集\n",
    ")\n",
    "# 为数据添加一个通道纬度，并且取值范围缩放到0-1之间\n",
    "test_data_x=test_data.data.type(torch.FloatTensor)/255\n",
    "test_data_x=torch.unsqueeze(test_data_x,dim=1)\n",
    "test_data_y=test_data.targets # 测试集的标签\n",
    "print(\"test_data_x.shape:\",test_data_x.shape)\n",
    "print(\"test_data_y.shape:\",test_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建一个卷积层神经网络\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()\n",
    "        # 定义第一个卷积层\n",
    "        self.convl=nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, # 输入的feature map\n",
    "                out_channels=16, # 输出的feature map\n",
    "                kernel_size=3, # 卷积核的尺寸\n",
    "                stride=1,# 卷积核的步长\n",
    "                padding=1,# 进行一个填充\n",
    "            ),\n",
    "            nn.ReLU(),# 激活函数\n",
    "            nn.AvgPool2d(\n",
    "                kernel_size=2, # 平均池池化层，使用2*2\n",
    "                stride=2, # 池化的步长为2\n",
    "            ),\n",
    "        )\n",
    "        # 定义第二个卷积层\n",
    "        self.conv2=nn.Sequential(\n",
    "            nn.Conv2d(16,32,3,1,1),\n",
    "            nn.ReLU(),# 激活函数\n",
    "            nn.MaxPool2d(2,2)# 最大值池化\n",
    "        )\n",
    "        # 定义全连接层\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=32*7*7, # 输入特征\n",
    "                out_features=128,# 输出特征数\n",
    "            ),\n",
    "            nn.ReLU(),# 激活函数\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU()# 激活函数\n",
    "        )\n",
    "        self.out=nn.Linear(64,10) # 最后的分类层\n",
    "    # 定义网络的向前传播路径\n",
    "    def forward(self,x):\n",
    "        x=self.convl(x)\n",
    "        x=self.conv2(x)\n",
    "        x=x.view(x.size(0),-1)# 展现多为的卷积图层\n",
    "        x=self.fc(x)\n",
    "        output=self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyConvnet=ConvNet()\n",
    "print(MyConvnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hiddenlayer as hl\n",
    "from graphviz import Digraph\n",
    "# 可视化卷积层神经网络\n",
    "hl_graph=hl.build_graph(MyConvnet,torch.zeros([1,1,28,28]))\n",
    "hl_graph.theme=hl.graph.THEMES[\"blue\"].copy()\n",
    "# 将可视化的网络保存为图片\n",
    "hl_graph.save(\"data/chap4/MyConvnet_hl.png\",format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "# 使用make——dot可视化网络\n",
    "x=torch.randn(1,1,28,28).requires_grad_(True)\n",
    "y=MyConvnet(x)\n",
    "MyConvnetvis=make_dot(y,params=dict(list(MyConvnet.named_parameters())+[('x',x)]))\n",
    "# 将MyConvnetvis保存为图片\n",
    "MyConvnetvis.format=\"png\"\n",
    "# 指定文件保存位置\n",
    "MyConvnetvis.directory=\"data/chap4/MyConvnet_vis\"\n",
    "MyConvnetvis.view()\n",
    "# 会自动生成当前文件夹生成文件\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从tensorboardX库中导入需要的API\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "SumWriter=SummaryWriter(log_dir=\"data/chap4/log\")\n",
    "# 定义一个优化器\n",
    "optimizer=torch.optim.Adam(MyConvnet.parameters(),lr=0.0003)\n",
    "loss_func=nn.CrossEntropyLoss() # 损失函数\n",
    "train_loss=0\n",
    "print_step=100 # 经过一百次迭代之后，输出损失\n",
    "# 对模型进行迭代训练，对所有的数据训练EPOCH轮\n",
    "for epoch in range(5):\n",
    "    # 对训练数据的加载器进行迭代计算\n",
    "    for step,(b_x,b_y) in enumerate(train_loader):\n",
    "        # 计算每个batch的损失\n",
    "        output=MyConvnet(b_x)# CNN在训练batch上的输出\n",
    "        loss=loss_func(output,b_y)# 交叉熵损失函数\n",
    "        optimizer.zero_grad()# 每一个迭代步有的梯度初始化为0\n",
    "        loss.backward() # 损失的后向传播，计算梯度\n",
    "        optimizer.step() # 利用梯度进行优化\n",
    "        train_loss=train_loss+loss # 计算损失的累加损失\n",
    "        # 计算迭代次数\n",
    "        niter=epoch*len(train_loader)+step+1\n",
    "        # 计算每经过print_step 此迭代后的输出\n",
    "        if niter%print_step==0:\n",
    "            # 为日志添加训练集损失函数\n",
    "            SumWriter.add_scalar(\"train_loss\",train_loss.item()/niter,global_step=niter)\n",
    "            # 计算在测试集上的精度\n",
    "            output=MyConvnet(test_data_x)\n",
    "            _,pre_lab=torch.max(output,1)\n",
    "            acc=accuracy_score(test_data_y,pre_lab)\n",
    "            # 为日志添加在测试集上的预测精度\n",
    "            SumWriter.add_scalar(\"test acc\",acc.item(),niter)\n",
    "            # 为日志中添加训练数据的可视化图像，使用当前batch的图像\n",
    "            # 将一个batch的数据进行预处理\n",
    "            b_x_im=vutils.make_grid(b_x,nrow=12)\n",
    "            SumWriter.add_image('train image sample',b_x_im,niter)\n",
    "            # 使用直方图可视化网络中参数的分布情况\n",
    "            for name,param in MyConvnet.named_parameters():\n",
    "                SumWriter.add_histogram(name,param.data.numpy(),niter)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-8-d418063302c0>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-d418063302c0>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import hiddenlayer as hl\n",
    "import time\n",
    "# 初始化MyConvnet\n",
    "MyConvnet=ConvNet()\n",
    "# 定义优化器\n",
    "optimizer=torch.optim.Adam(MyConvnet.parameters(),lr=0.0003)\n",
    "loss_func=nn.CrossEntropyLoss() # 损失函数\n",
    "# 记录训练过程的指标\n",
    "history1=hl.History()\n",
    "# 使用Canvas进行客户丝滑\n",
    "canvasl1=hl.History()\n",
    "print_step=100 # 每次经过一百次迭代之后，输出损失\n",
    "# 对模型进行迭代训练，对所有数据训练epoch轮\n",
    "for epoch in range(5):\n",
    "    # 对训练数据的加载器进行迭代计算\n",
    "    for step,(b_x,b_y) in enumerate(train_loader):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a04f5d07b0747026a8fbcdf50b9443318e69b1b8bd6247d88bfadb4789282972"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
