{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入本节所需要的模块\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torch.utils.data as Data\n",
    "from torchvision import transforms\n",
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-59907f20131b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# 准备训练数据集MNIST\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m train_data=torchvision.datasets.MNIST(\n\u001B[0m\u001B[0;32m      3\u001B[0m     \u001B[0mroot\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"./data/FashionMNIST/MNIST\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mtrain\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mtransform\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mToTensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\conda\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, root, train, transform, target_transform, download)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     81\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_exists\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 82\u001B[1;33m             raise RuntimeError('Dataset not found.' +\n\u001B[0m\u001B[0;32m     83\u001B[0m                                ' You can use download=True to download it')\n\u001B[0;32m     84\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "# 准备训练数据集MNIST\n",
    "train_data=torchvision.datasets.MNIST(\n",
    "    root=\"./data/FashionMNIST/MNIST\",\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=False\n",
    ")\n",
    "# 定义一个数据加载器\n",
    "train_loader=Data.DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "# 准备需要使用的测试数据集\n",
    "test_data=torchvision.datasets.MNIST(\n",
    "    root=\"./data/MNIST\",\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=False\n",
    ")\n",
    "# 定义一个数据加载器\n",
    "test_loader=Data.DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNimc(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,layer_dim,output_dim):\n",
    "        \"\"\"\n",
    "        input_dim:输入数据的维度（图片每行的数据像素点）\n",
    "        hidden_dim:RNN神经元的个数\n",
    "        layer_dim:RNN的层数\n",
    "        output_dim:隐藏层输出的维度（分类的数据）\n",
    "        \"\"\"\n",
    "        super(RNNimc,self).__init__()\n",
    "        self.hidden_dim=hidden_dim# RNN神经元个数\n",
    "        self.layer_dim=layer_dim# RNN的层数\n",
    "        # RNN\n",
    "        self.rnn=nn.RNN(input_dim,hidden_dim,layer_dim,batch_first=True,nonlinearity='relu')\n",
    "        # 连接全连接层\n",
    "        self.fc1=nn.Linear(hidden_dim,output_dim)\n",
    "    def forward(self,x):\n",
    "        # x:[batch,time_step,input_dim]\n",
    "        # 本例子time_step=图像所有像素数量/input_dim\n",
    "        # out:[batch,time_step,output_siez]\n",
    "        # h_n:[layer_dim,bacth,hidden_dim]\n",
    "        out,h_n=self.rnn(x,None)\n",
    "        # 选取最后一个时间点的out输出\n",
    "        out=self.fc1(out[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型的调用\n",
    "input_dim=28 # 图片每行的像素数量\n",
    "hidden_dim=128# RNN神经元个数\n",
    "layer_dim=1# RNN的层数\n",
    "output_dim=10# 隐藏层输出的维度（10类图像）\n",
    "MyRNNimc=RNNimc(input_dim,hidden_dim,layer_dim,output_dim)\n",
    "print(MyRNNimc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化卷积神经网络，输入：[batch,time_step,input_dim]\n",
    "hl_graph=hl.build_graph(MyRNNimc,torch.zeros([1,28,28]))\n",
    "hl_graph.theme=hl.graph.THEMES[\"blue\"].copy()\n",
    "hl_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对模型进行训练\n",
    "optimizer=torch.optim.RMSprop(MyRNNimc.parameters(),lr=0.0003)\n",
    "criterion=nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "train_loss_all=[]\n",
    "train_acc_all=[]\n",
    "test_loss_all=[]\n",
    "test_acc_all=[]\n",
    "num_epochs=30\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch{}/{}'.format(epoch,num_epochs-1))\n",
    "    MyRNNimc.train() # 设置模型为训练模式\n",
    "    corrects=0\n",
    "    train_num=0\n",
    "    for step,(b_x,b_y) in enumerate(train_loader):\n",
    "        # input :[bacth,time_step,input_dim]\n",
    "        xdata=b_x.view(-1,28,28)\n",
    "        output=MyRNNimc(xdata)\n",
    "        pre_lab=torch.argmax(output,1)\n",
    "        loss=criterion(output,b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss+=loss.item()*b_x.size(0)\n",
    "        corrects+=torch.sum(pre_lab==b_y.data)\n",
    "        train_num+=b_x.size(0)\n",
    "    # 计算进过一个epoch的训练之后在训练集上的损失和精度\n",
    "    train_loss_all.append(loss/train_num)\n",
    "    train_acc_all.append(corrects.double().item()/train_num)\n",
    "    print('{} Train Loss: {:.4f} Train Acc: {:.4f}'\n",
    "    .format(epoch,train_loss_all[-1],train_acc_all[-1]))\n",
    "    # 设置模型为验证模式\n",
    "    MyRNNimc.eval()\n",
    "    corrects=0\n",
    "    test_num=0\n",
    "    for step,(b_x,b_y) in enumerate(test_loader):\n",
    "        # input:[batch ,time_step, input_dim]\n",
    "        xdata=b_x.viwe(-1,28,28)\n",
    "        output=MyRNNimc(xdata)\n",
    "        pre_lab=torch.argmax(output,1)\n",
    "        loss=criterion(output,b_y)\n",
    "        loss+=loss.item()*b_x.size(0)\n",
    "        corrects+=torch.sum(pre_lab==b_y.data)\n",
    "        test_num+=b_x.size(0)\n",
    "    # 计算经过一个epoch的训练后在测试集上的损失和精度\n",
    "    test_loss_all.append(loss/test_num)\n",
    "    test_acc_all.append(corrects.double().item()/test_num)\n",
    "    print('{} Test Loss: {:.4f} Test Acc: {:.4f}'.format(\n",
    "        epoch,test_loss_all[-1],test_acc_all[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化模型训练过程\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_loss_all,\"ro-\",label=\"Train loss\")\n",
    "plt.plot(test_loss_all,\"bs-\",label=\"Val loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_acc_all,\"ro-\",label=\"Train acc\")\n",
    "plt.plot(test_acc_all,\"bs-\",label=\"Val acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a04f5d07b0747026a8fbcdf50b9443318e69b1b8bd6247d88bfadb4789282972"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
