{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3507b279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:09.878074Z",
     "start_time": "2022-04-15T07:58:08.316644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "# 改变张量的形状\n",
    "\n",
    "A=torch.arange(12.0)\n",
    "A=A.reshape(3,4)\n",
    "print(torch.arange(12.0).reshape(3,4))\n",
    "print(A)\n",
    "A.resize_(2,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8665106",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:09.894086Z",
     "start_time": "2022-04-15T07:58:09.879075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.,  9., 10., 11.]])\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.,  9., 10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "torch.reshape(input=A,shape=(2,6))\n",
    "print(torch.reshape(input=A,shape=(2,6)))\n",
    "print(torch.reshape(input=A,shape=(2,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a8488ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:09.910091Z",
     "start_time": "2022-04-15T07:58:09.896085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "# 改变张量的形状\n",
    "A=torch.arange(12.0).reshape(3,4)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93c23a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:09.925642Z",
     "start_time": "2022-04-15T07:58:09.911091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.,  9., 10., 11.]])\n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[10., 11., 12.],\n",
       "        [13., 14., 15.],\n",
       "        [16., 17., 18.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.resize_(2,6)\n",
    "print(A)\n",
    "B=torch.arange(10.0,19.0).reshape(3,3)\n",
    "A.resize_as_(B)\n",
    "print(A)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "291a0d61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:09.941692Z",
     "start_time": "2022-04-15T07:58:09.926644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6])\n",
      "torch.Size([1, 2, 6])\n",
      "tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "         [ 6.,  7.,  8.,  9., 10., 11.]]])\n",
      "C.shape: torch.Size([1, 2, 6, 1])\n",
      "D.shape: torch.Size([2, 6])\n",
      "E.shape: torch.Size([1, 1, 2, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "A=torch.arange(12.0).reshape(2,6)\n",
    "print(A.shape)\n",
    "B=torch.unsqueeze(A,dim=-3)\n",
    "print(B.shape)\n",
    "# 这里的意思是用unsqueeze函数实现插入尺寸为一的新张量\n",
    "B.shape\n",
    "B.size()\n",
    "print(B)\n",
    "B.numel()\n",
    "C=B.unsqueeze(dim=3)\n",
    "# 移除尺所有维度为1的张量\n",
    "print(\"C.shape:\",C.shape)\n",
    "D=torch.squeeze(C)\n",
    "print(\"D.shape:\",D.shape)\n",
    "E=torch.unsqueeze(C,dim=0)\n",
    "print(\"E.shape:\",E.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf91c873",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:09.957797Z",
     "start_time": "2022-04-15T07:58:09.942694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=torch.arange(3)\n",
    "# 创建一个一维相量\n",
    "B=A.expand(3,-1)# 3或者-1\n",
    "#  -1 不改变原来的尺寸（非单例尺寸）\n",
    "# 这里里面的是数字可以任意改变，与下面对应，但是末尾的那个不行，只能是跟前面对应上\n",
    "B\n",
    "B.shape\n",
    "# expand()方法用于拓展维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf4a20f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:09.973300Z",
     "start_time": "2022-04-15T07:58:09.958799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [0, 1, 2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=torch.arange(6).reshape(2,3)\n",
    "B=A.expand_as(C)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a4f7892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:09.988305Z",
     "start_time": "2022-04-15T07:58:09.975302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[[[0, 1, 2, 0, 1, 2],\n",
      "          [0, 1, 2, 0, 1, 2],\n",
      "          [0, 1, 2, 0, 1, 2],\n",
      "          [0, 1, 2, 0, 1, 2]],\n",
      "\n",
      "         [[0, 1, 2, 0, 1, 2],\n",
      "          [0, 1, 2, 0, 1, 2],\n",
      "          [0, 1, 2, 0, 1, 2],\n",
      "          [0, 1, 2, 0, 1, 2]]]])\n",
      "torch.Size([1, 2, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "C=torch.arange(6).reshape(2,3)\n",
    "B=A.expand_as(C)\n",
    "print(B.shape)\n",
    "D=B.repeat(1,2,2,2)\n",
    "# tensor.repeat(size)这个的意思是把张量看成一个整体，然后根据指定的形状进行重复填充,\n",
    "# The number of times to repeat this tensor along each dimension\n",
    "print(D)\n",
    "print(D.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2457debe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:10.004308Z",
     "start_time": "2022-04-15T07:58:09.989306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4])\n",
      "\n",
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]]])\n",
      "\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "\n",
      "tensor([ 8,  9, 10])\n"
     ]
    }
   ],
   "source": [
    "# 获取张量之中的元素\n",
    "A=torch.arange(12).reshape(1,3,4)\n",
    "print(A.shape)\n",
    "print()\n",
    "print(A)\n",
    "print()\n",
    "print(A[0])\n",
    "print()\n",
    "# 获取第0维度之下的矩阵元素,第n维度为第n+1的层\n",
    "print(A[0,0:2,:-1])\n",
    "print()\n",
    "# 获取第0维度下的前两行元素\n",
    "print(A[0,0:2,:])\n",
    "print()\n",
    "# 获取第零维度下的矩阵，最后一行的-4到-1列\n",
    "print(A[0,-1,-4:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "848a5ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:10.019312Z",
     "start_time": "2022-04-15T07:58:10.005309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]]])\n",
      "\n",
      " tensor([[[ 0, -1, -2, -3],\n",
      "         [-4, -5,  6,  7],\n",
      "         [ 8,  9, 10, 11]]])\n",
      "\n",
      " tensor([ 6,  7,  8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "# 在pytorch里面的话可以将索引设置为读研的布尔值，提取真值的内容\n",
    "print(A)\n",
    "B=-A\n",
    "torch.where(A>5,A,B)\n",
    "print('\\n',torch.where(A>5,A,B))\n",
    "# 当A>5的时候为TRUE返回x对应位置值，为FALSE的时候为y的值\n",
    "print('\\n',A[A>5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "397c74ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:10.035315Z",
     "start_time": "2022-04-15T07:58:10.020313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]]])\n",
      "\n",
      " tensor([[[ 0,  0,  0,  0],\n",
      "         [ 4,  5,  0,  0],\n",
      "         [ 8,  9, 10,  0]]])\n",
      "\n",
      " tensor([[[ 0,  1,  0,  0],\n",
      "         [ 4,  5,  6,  0],\n",
      "         [ 8,  9, 10, 11]]])\n",
      "\n",
      " tensor([[[ 0,  0,  0,  0],\n",
      "         [ 4,  5,  0,  0],\n",
      "         [ 8,  9, 10,  0]]])\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "torch.tril(A,diagonal=0)\n",
    "print('\\n',torch.tril(A,diagonal=0))\n",
    "# 获取张量下三角的内容，将上三角的元素全部放置为0。\n",
    "\n",
    "torch.tril(A,diagonal=1)\n",
    "print('\\n',torch.tril(A,diagonal=1))\n",
    "# diagonal参数控制要考虑的对角线,对角线没有放置为0\n",
    "\n",
    "torch.triu(A,diagonal=0)\n",
    "print('\\n',torch.tril(A,diagonal=0))\n",
    "# 获取矩阵张量上三角的部分，对角线放置为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9ad7293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:10.051318Z",
     "start_time": "2022-04-15T07:58:10.036315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]]) \n",
      "\n",
      "tensor([ 0,  5, 10]) \n",
      "\n",
      "tensor([ 1,  6, 11]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "C=A.reshape(3,4)\n",
    "print(C,'\\n')\n",
    "# 函数里面必须是二维张量\n",
    "print(torch.diag(C,diagonal=0),'\\n')\n",
    "print(torch.diag(C,diagonal=1),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e833ae45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:10.066322Z",
     "start_time": "2022-04-15T07:58:10.052318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 2, 0],\n",
       "        [0, 0, 3]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(torch.tensor([1,2,3]))\n",
    "# 提供对角线元素生成矩阵向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4b1a438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:10.082325Z",
     "start_time": "2022-04-15T07:58:10.067322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]) \n",
      "\n",
      "tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]]) \n",
      "\n",
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]]) \n",
      "\n",
      "tensor([[ 0.,  1.,  2.,  0.,  2.,  4.],\n",
      "        [ 3.,  4.,  5.,  6.,  8., 10.]]) \n",
      "\n",
      "tensor([[ 1.,  0.,  1.,  2.,  0.,  2.,  4.],\n",
      "        [ 4.,  3.,  4.,  5.,  6.,  8., 10.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 拼接与拆分\n",
    "A=torch.arange(6).reshape(2,3)\n",
    "print(A,'\\n')\n",
    "B=torch.linspace(0,10,6).reshape(2,3)\n",
    "print(B,'\\n')\n",
    "# 在0维连接张量,这里的意思是在各自的维度里面进行连接的意思，即为A,B里面的维度进行连接\n",
    "C=torch.cat((A,B),dim=0)\n",
    "print(C,'\\n')\n",
    "# 在1维连接张量\n",
    "D=torch.cat((A,B),dim=1)\n",
    "print(D,'\\n')\n",
    "E=torch.cat((A[:,1:2],A,B),dim=1)\n",
    "print(E,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21f481f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T07:58:10.097329Z",
     "start_time": "2022-04-15T07:58:10.083325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  2.,  4.],\n",
       "        [ 6.,  8., 10.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=torch.linspace(0,10,6).reshape(2,3)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3028e78b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T08:11:09.582286Z",
     "start_time": "2022-04-15T08:11:09.571285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]) \n",
      "\n",
      "tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]]) \n",
      "\n",
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]]) \n",
      "\n",
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 0.,  2.,  4.],\n",
      "         [ 6.,  8., 10.]]]) \n",
      "\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(A,'\\n')\n",
    "print(B,'\\n')\n",
    "F=torch.stack((A,B),dim=0)\n",
    "# torch.stack将多个张量按照指定维度进行拼接,意思是新建一个维度进行相加\n",
    "# 沿新维度连接张量\n",
    "C=torch.cat((A,B),dim=0)\n",
    "print(C,'\\n')\n",
    "print(F,'\\n')\n",
    "print(F.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ff06e25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T08:32:25.982363Z",
     "start_time": "2022-04-15T08:32:25.976606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1.],\n",
      "        [4., 3., 4.]])\n",
      "tensor([[2., 0., 2.],\n",
      "        [5., 6., 8.]])\n",
      "tensor([[ 4.],\n",
      "        [10.]])\n"
     ]
    }
   ],
   "source": [
    "# print(E,'\\n')\n",
    "F1,F2=torch.chunk(E,2,dim=0)\n",
    "# print(F1,'\\n')\n",
    "# print(F2,'\\n')\n",
    "# print(D,'\\n')\n",
    "D1,D2=torch.chunk(D,2,dim=1)\n",
    "# print(D1,'\\n')\n",
    "# print(D2,'\\n')\n",
    "E1,E2,E3=torch.chunk(E,3,dim=1)\n",
    "print(E1)\n",
    "print(E2)\n",
    "print(E3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b823aba9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T08:34:23.214009Z",
     "start_time": "2022-04-15T08:34:23.193004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [3.]])\n",
      "tensor([[1., 2.],\n",
      "        [4., 5.]])\n",
      "tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]])\n"
     ]
    }
   ],
   "source": [
    "D1,D2,D3=torch.split(D,[1,2,3],dim=1)\n",
    "print(D1)\n",
    "print(D2)\n",
    "print(D3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7163bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
