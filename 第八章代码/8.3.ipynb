{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入本节所需要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.util import random_noise\n",
    "from skimage.measure import compare_psnr\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import STL10\n",
    "import hiddenlayer as hl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个将bin文件处理为图像数据的函数\n",
    "def read_image(data_path):\n",
    "    with open(data_path,'rb') as f:\n",
    "        data1=np.fromfile(f,dtype=np.uint8)\n",
    "        # 图像[数量，通道，宽，高]\n",
    "        images=np.reshape(data1,(-1,3,96,96))\n",
    "        # 图像转化为RGB模式，方便用matplotlib进行可视化\n",
    "        images=np.transpose(images,(0,3,2,1))\n",
    "    # 输出的图像取在0-1之间\n",
    "    return images/225.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练数据集,5000张96*96*96*3的图像\n",
    "data_path=\"data/STL10/stl10_binary/train_X.bin\"\n",
    "images=read_image(data_path)\n",
    "print(\"image.shape:\",images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为数据添加高斯噪声\n",
    "def gaussian_noise(images,sigma):\n",
    "    \"\"\"sigma:噪声标准差\"\"\"\n",
    "    sigma2=sigma**2/(225**2)# 噪声方差\n",
    "    images_noisy=np.zeros_like(images)\n",
    "    for ii in range(images.shape[0]):\n",
    "        image=images[ii]\n",
    "        # 使用skimage库中的random_noise函数添加噪声\n",
    "        noise_im=random_noise(image,mode=\"gaussian\",var=sigma2,clip=True)\n",
    "        images_noisy[ii]=noise_im\n",
    "    return images_noisy\n",
    "images_noise=gaussian_noise(images,30)\n",
    "print(\"image_noises:\",images_noise.min(),\"~\",images_noise.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化其中的部分图像，不带噪声的图像\n",
    "plt.figure(figsize=(6,6))\n",
    "for ii in np.arange(36):\n",
    "    plt.subplot(6,6,ii+1)\n",
    "    plt.imshow(imagesp[ii,...])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "# 带噪声的图像\n",
    "plt.figure(figsize=(6,6))\n",
    "for ii in np.arange(36):\n",
    "    plt.subplot(6,6,ii+1)\n",
    "    plt.imshow(images_noise[ii,...])\n",
    "    plt.show(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备为PyTorch可用的形式，转化为[样本，通道，高，宽]的数据形式\n",
    "data_Y=np.transpose(images,(0,3,2,1))\n",
    "data_X=np.transpose(images_noise,(0,3,3,1))\n",
    "# 将数据集且分为训练集和验证集\n",
    "X_train,X_val,y_train,y_val=train_test_split(data_X,data_Y,test_size=0.2,random_state=123)\n",
    "# 将图像数据转化为向量数据\n",
    "X_train=torch.tensor(X_train,dtype=torch.float32)\n",
    "y_train=torch.tensor(y_train,dtype=torch.float32)\n",
    "X_val=torch.tensor(X_val,dtype=torch.float32)\n",
    "y_val=torch.tensor(y_val,dtype=torch.float32)\n",
    "# 将X和Y转化为数据集合\n",
    "train_data=Data.TensorDataset(X_train,y_train)\n",
    "val_data=Data.TensorDataset(X_val,y_val)\n",
    "print(\"X_train.shape:\",X_train.shape)\n",
    "print(\"y_train.shape:\",y_train.shape)\n",
    "print(\"X_val.shape:\",X_val.shape)\n",
    "print(\"y_val.shape:\",y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个数据加载器\n",
    "train_loader=Data.DataLoader(\n",
    "    dataset=train_data,# 使用的数据集\n",
    "    batch_size=32,# 批处理样本大小\n",
    "    shuffle=True,# 每次迭代前打乱数据\n",
    "    num_workers=4,# 每次使用4个进程\n",
    ")\n",
    "# 定义一个数据加载器\n",
    "val_loader=Data.DataLoader(\n",
    "    dataset=val_data,# 使用的数据集\n",
    "    batch_size=32,# 批处理的样本大小\n",
    "    shuffle=True,# 每次迭代之前打乱数据\n",
    "    num_workers=4,# 每次使用四个进程\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoiseAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoiseAutoEncoder,self).__init__()\n",
    "        # 定义Encoder\n",
    "        self.Encoder=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=64,\n",
    "            kernel_size=3,stride=1,padding=1),# [,64,96,96]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64,64,3,1,1),#[,64,96,96]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64,64,3,1,1),#[,64,96,96]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),# [,64,48,48]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64,128,3,1,1),# [,128,48,48]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128,128,3,1,1),# [,128,48,48]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128,256,3,1,1),# [,256,48,48]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),# [,256,24,24]\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "        # 定义Decoder\n",
    "        self.Decoder=nn.Sequential(\n",
    "            nn.ConvTranspose2d(256,128,3,1,1),# [,256,24,24]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128,128,3,2,1,1),# [,128,48,48]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128,64,3,1,1),# [,64,48,48]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ConvTranspose2d(64,32,3,1,1),# [,32,48,48]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ConvTranspose2d(32,32,3,1,1),# [,32,48,48]\n",
    "            nn.ConvTranspose2d(32,16,3,2,1,1),# [,16,96,96]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ConvTranspose2d(16,3,3,1,1),# [,3,96,96]\n",
    "            nn.Sigmoid(), \n",
    "        )\n",
    "    # 定义网络的前向传播路径\n",
    "    def forward(self,x):\n",
    "        encoder=self.Encoder(x)\n",
    "        decoder=self.Decoder(encoder)\n",
    "        return encoder,decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAEmodel=DenoiseAutoEncoder()\n",
    "print(DAEmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器\n",
    "LR=0.0003\n",
    "optimizer=torch.optim.Adam(DAEmodel.parameters(),lr=LR)\n",
    "loss_func=nn.MSELoss()# 损失函数\n",
    "# 记录训练过程的指标\n",
    "historyl=hl.History()\n",
    "# 使用Canvas进行可视化\n",
    "canvasl=hl.Canvas()\n",
    "train_num=0\n",
    "val_num=0\n",
    "# 对模型进行迭代训练，对所有数据训练epoch轮\n",
    "for epoch in range(10):\n",
    "    train_loss_epoch=0\n",
    "    val_loss_epoch=0\n",
    "    # 对训练数据的加载器进行迭代计算\n",
    "    for step,(b_x,b_y) in  enumerate(train_loader):\n",
    "        DAEmodel.train()\n",
    "        # 使用每个batch进行训练模型\n",
    "        _,output=DAEmodel(b_x) # CNN在训练batch上的输出，网络返回encoder,decoder\n",
    "        loss=loss_func(output,b_y) # 均方根误差\n",
    "        optimizer.zero_grad() # 每个迭代步的梯度初始化为0\n",
    "        loss.backward() # 损失的后向传播，计算梯度\n",
    "        optimizer.step() # 使用梯度进行优化\n",
    "        train_loss_epoch+=loss.item()*b_x.size(0)\n",
    "        train_num=train_num+b_x.size(0)\n",
    "    # 使用每个batch进行验证模型\n",
    "    for step,(b_x,b_y) in  enumerate(val_loader):\n",
    "        DAEmodel.eval()\n",
    "        _,output=DAEmodel(b_x) # （卷积神经网络）CNN在训练batch上的输出\n",
    "        loss=loss_func(output,b_y)# 均方根误差\n",
    "        val_loss_epoch+=loss.item()*b_x.size(0)\n",
    "        val_num=val_num+b_x.size(0)\n",
    "    # 计算一个epoch的损失\n",
    "    train_loss=train_loss_epoch/train_num\n",
    "    val_loss=val_loss_epoch/val_num\n",
    "    # 保存每一个epoch上的输出loss\n",
    "    historyl.log(epoch,train_loss=train_loss,val_loss=val_loss)\n",
    "# 可视化网络训练过程\n",
    "with canvasl:\n",
    "    canvasl.draw_plot([historyl[\"train_loss\"],historyl[\"val_loss\"]])\n",
    "        \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入\n",
    "imageindex=1\n",
    "im=X_val[imageindex,...]\n",
    "im=im.unsqueeze(0)\n",
    "imnose=np.transpose(im.data.numpy(),(0,3,2,1))\n",
    "imnose=imnose[0,...]\n",
    "# 去噪\n",
    "DAEmodel.eval()\n",
    "_,output=DAEmodel(im)\n",
    "imde=np.transpose(output.data.numpy(),(0,3,2,1))\n",
    "imde=imde[0,...]\n",
    "# 输出\n",
    "im=y_val[imageindex,...]\n",
    "imor=im.unsqueeze(0)\n",
    "imor=np.transpose(imor.data.numpy(),(0,3,2,1))\n",
    "imor=imor[0,...]\n",
    "# 计算去噪后的PSNR\n",
    "print(\"加噪之后PSNR:\",compare_psnr(imor,imnose),\"dB\")\n",
    "print(\"去噪之后PSNR:\",compare_psnr(imor,imde),\"dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将图像可视化\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(imor)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Origin image\")1\n",
    "plt.imshow(imnose)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Noise image $\\sigmas$=30\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(imde)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Denoise image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算模型对整个验证集去噪之后的PSNR提升量的均值\n",
    "PSNR_val=[]\n",
    "DAEmodel.eval()\n",
    "for ii in range(X_val.shape[0]):\n",
    "    imageindex=ii\n",
    "    # 输入\n",
    "    im=X_val[imageindex,...]\n",
    "    im=im.unsqueeze(0)\n",
    "    imnose=np.transpose(im.data.numpy(),(0,3,2,1))\n",
    "    imnose=imnose[0,...]\n",
    "    # 去噪\n",
    "    _,output=DAEmodel(im)\n",
    "    imde=np.transpose(output.data.numpy(),(0,3,2,1))\n",
    "    imde=imde[0,...]\n",
    "    # 输出\n",
    "    im=y_val[imageindex,...]\n",
    "    imor=im.unsqueeze(0)\n",
    "    imor=np.transpose(imor.data.numpy(),(0,3,2,1))\n",
    "    imor=imor[0,...]\n",
    "    # 计算去噪之后的PSNR\n",
    "    PSNR_val.append(compare_psnr(imor,imde)-compare_psnr(imor,imnose))\n",
    "print(\"PSNR的平均提升量为\",np.mean(PSNR_val),\"dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-da85b237114e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mDenoiseAutoEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDenoiseAutoEncoder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m# 定义Encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class DenoiseAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoiseAutoEncoder,self).__init__()\n",
    "        # 定义Encoder\n",
    "        self.Encoder=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=64,\n",
    "            kernel_size=3,stride=1,padding=1\n",
    "            ),# [,64,96,96]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64,64,3,1,1),# [,64,96,96]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64,64,3,1,1),# [,64,48,48]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(64),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64,128,3,1,1),# [,128,48,48]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(64,128,3,1,1),# [,128,48,48]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128,128,3,1,1),# [,128,48,48]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128,256,3,1,1),# [,256,48,48]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),# [,256,24,24]\n",
    "            nn.BatchNorm2d(256)\n",
    "        )\n",
    "        # 定义Decoder\n",
    "        self.Decoder=nn.Sequential(\n",
    "            nn.UpsamplingBilinear2d(scale_factor=2),# [,256,48,48]\n",
    "            nn.Conv2d(256,128,3,1,1),# [,128,48,48]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128,64,3,1,1),# [,128,48,48]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.UpsamplingBilinear2d(scale_factor=2),# [,64,96,96]\n",
    "            nn.Conv2d(64,32,3,1,1),# [,32,96,96]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32,3,3,1,1),# [,3,96,96]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    # 定义网络的前向传播路径\n",
    "    def forward(self,x):\n",
    "        encoder=self.Encoder(x)\n",
    "        decoder=self.Decoder(encoder)\n",
    "        return encoder,decoder\n",
    "# 初始化网络结构\n",
    "DAEmodel=DenoiseAutoEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器\n",
    "LR=0.0003\n",
    "optimizer=torch.optim.Adam(DAEmodel.parameters(),lr=LR)\n",
    "loss_func=nn.MSELoss() # 损失函数\n",
    "# 记录训练过程的指标\n",
    "historyl=hl.History()\n",
    "# 使用Canvas进行可视化\n",
    "canvasl=hl.Canvas()\n",
    "train_num=0\n",
    "val_num=0\n",
    "# 对模型进行迭代训练，对所有数据训练epoch轮\n",
    "for epoch in range(10):\n",
    "    train_loss_epoch=0\n",
    "    val_loss_epoch=0\n",
    "    # 对模型进行迭代训练，对所有的数据训练epoch轮\n",
    "    for step,(b_x,b_y) in enumerate(train_loader):\n",
    "        DAEmodel.train()\n",
    "        # 使用每个batch进行训练模型\n",
    "        _,output=DAEmodel(b_x),# CNN在batch上的输出\n",
    "        loss=loss_func(output,b_y) # 均方根误差\n",
    "        optimizer.zero_grad() # 每个迭代步的梯度初始化为0\n",
    "        loss.backward() # 损失的后向传播,计算梯度\n",
    "        optimizer.step()\n",
    "        train_loss_epoch+=loss.item()*b_x.size(0)\n",
    "        train_num=train_num+b_x.size(0)\n",
    "    # 使用每个batch进行验证模型\n",
    "    for step,(b_x,b_y) in enumerate(val_loader):\n",
    "        DAEmodel.eval()\n",
    "        _,output=DAEmodel(b_x)# CNN在训练batch上的输出\n",
    "        loss=loss_func(output,b_y) # 均方根误差\n",
    "        val_loss_epoch+=loss.item()*b_x.size(0)\n",
    "        val_num=val_num+b_x.size(0)\n",
    "    # 计算一个epoch损失\n",
    "    train_loss=train_loss_epoch/train_num\n",
    "    val_loss=val_loss_epoch/val_num\n",
    "    # 保存每个epoch上的输出loss\n",
    "    historyl.log(epoch,train_loss=train_loss,val_loss=val_loss)\n",
    "# 可视化网络训练的过程\n",
    "with canvasl:\n",
    "    canvasl.draw_plot([historyl[\"train_loss\"],historyl[\"val_loss\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入\n",
    "imageindex=1\n",
    "im=X_val[imageindex,...]\n",
    "im=im.unsqueeze(0)\n",
    "imnose=np.transpose(im.data.numpy(),(0,3,2,1))\n",
    "imnose=imnose[0,...]\n",
    "# 去噪\n",
    "DAEmodel.eval()\n",
    "_,output=DAEmodel(im)\n",
    "imde=np.transpose(output.data.numpy(),(0,3,2,1))\n",
    "imde=imde[0,...]\n",
    "# 输出\n",
    "im=y_val[imageindex,...]\n",
    "imor=im.unsqueeze(0)\n",
    "imor=np.transpose(imor.data.numpy(),(0,3,2,1))\n",
    "imor=imor[0,...]\n",
    "# 计算去噪后的PSNR\n",
    "print(\"加噪之后PSNR:\",compare_psnr(imor,imnose),\"dB\")\n",
    "print(\"去噪之后PSNR:\",compare_psnr(imor,imde),\"dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将图像可视化\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(imor)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Origin image\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(imnose)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Noise image $\\sigmas$=30\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(imde)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Denoise image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算模型对整个验证集去噪之后的PSNR提升量的均值\n",
    "PSNR_val=[]\n",
    "DAEmodel.eval()\n",
    "for ii in range(X_val.shape[0]):\n",
    "    imageindex=ii\n",
    "    # 输入\n",
    "    im=X_val[imageindex,...]\n",
    "    im=im.unsqueeze(0)\n",
    "    imnose=np.transpose(im.data.numpy(),(0,3,2,1))\n",
    "    imnose=imnose[0,...]\n",
    "    # 去噪\n",
    "    _,output=DAEmodel(im)\n",
    "    imde=np.transpose(output.data.numpy(),(0,3,2,1))\n",
    "    imde=imde[0,...]\n",
    "    # 输出\n",
    "    im=y_val[imageindex,...]\n",
    "    imor=im.unsqueeze(0)\n",
    "    imor=np.transpose(imor.data.numpy(),(0,3,2,1))\n",
    "    imor=imor[0,...]\n",
    "    # 计算去噪之后的PSNR\n",
    "    PSNR_val.append(compare_psnr(imor,imde)-compare_psnr(imor,imnose))\n",
    "print(\"PSNR的平均提升量为\",np.mean(PSNR_val),\"dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a04f5d07b0747026a8fbcdf50b9443318e69b1b8bd6247d88bfadb4789282972"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
